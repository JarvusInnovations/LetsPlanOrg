{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 This will be the home of LetsPlan.org\u2019s technical documentation.","title":"Welcome"},{"location":"#welcome","text":"This will be the home of LetsPlan.org\u2019s technical documentation.","title":"Welcome"},{"location":"development/getting-started/","text":"Getting Started \u00b6 Quick start \u00b6 Initialize new .env file: cp .env.example .env !!! tip Change the web port from 7780 to something unsused if you have a port conflict. Change the MailHog web port from 8725 to something unsused if you have a port conflict. If you have another Postgres running on 5432, add a line to your .env like `FORWARD_DB_PORT=5433` Configure .env to use online database and map tiles so you can skip loading data and building tiles locally: MBTILE_URL = \"https://letsplan.live.k8s.jarv.us/urban/{z}/{x}/{y}.pbf\" MIX_MBTILE_URL = \" ${ MBTILE_URL } \" DB_HOST = WORKSTATION_LAN_IP DB_PORT = 5433 DB_USERNAME = read_only DB_PASSWORD = FROM_BITWARDEN The password is available in BitWarden under the entry read_only @ postgresql Use Docker to install PHP dependencies: docker run -ti --rm -v $( pwd ) :/app -w /app composer:2.0 composer install Open a tunnel from the online PostgreSQL database to local port 5433 : export KUBECONFIG = ~/.kube/letsplan-deployer.yaml DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $DB_POD --address 0 .0.0.0 5433 :5432 Download letsplan-deployer.yaml from the letsplan-deployer @ jarvus-live-cluster entry in BitWarden Start local Docker environment with Laravel Sail: ./vendor/bin/sail up -d Generate unique local app key: ./vendor/bin/sail artisan key:generate Install frontend dependencies: ./vendor/bin/sail yarn install Execute a frontend build: ./vendor/bin/sail yarn production","title":"Getting Started"},{"location":"development/getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"development/getting-started/#quick-start","text":"Initialize new .env file: cp .env.example .env !!! tip Change the web port from 7780 to something unsused if you have a port conflict. Change the MailHog web port from 8725 to something unsused if you have a port conflict. If you have another Postgres running on 5432, add a line to your .env like `FORWARD_DB_PORT=5433` Configure .env to use online database and map tiles so you can skip loading data and building tiles locally: MBTILE_URL = \"https://letsplan.live.k8s.jarv.us/urban/{z}/{x}/{y}.pbf\" MIX_MBTILE_URL = \" ${ MBTILE_URL } \" DB_HOST = WORKSTATION_LAN_IP DB_PORT = 5433 DB_USERNAME = read_only DB_PASSWORD = FROM_BITWARDEN The password is available in BitWarden under the entry read_only @ postgresql Use Docker to install PHP dependencies: docker run -ti --rm -v $( pwd ) :/app -w /app composer:2.0 composer install Open a tunnel from the online PostgreSQL database to local port 5433 : export KUBECONFIG = ~/.kube/letsplan-deployer.yaml DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $DB_POD --address 0 .0.0.0 5433 :5432 Download letsplan-deployer.yaml from the letsplan-deployer @ jarvus-live-cluster entry in BitWarden Start local Docker environment with Laravel Sail: ./vendor/bin/sail up -d Generate unique local app key: ./vendor/bin/sail artisan key:generate Install frontend dependencies: ./vendor/bin/sail yarn install Execute a frontend build: ./vendor/bin/sail yarn production","title":"Quick start"},{"location":"development/k8s/","text":"Kubernetes \u00b6 Create a disposable local Kubernetes environment: kind create cluster Install Helm chart: helm install letsplan ./helm-chart \\ --set workloads.app.secrets.app = letsplan-dev \\ --set images.app.repository = ghcr.io/jarvusinnovations/letsplanorg/laravel-site !!! warning Kind is incompatible with docker.pkg.github.com and the urbanSpatial organization does not have ghcr.io support enabled The above command overrides the release to use a ghcr.io-hosted image under Jarvus' organization. This image is not automatically updated when new versions are pushed/released on the urbanSpatial organization and must have updated container images manually pushed. Generate APP_KEY secret and restart pod: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) APP_KEY = $( kubectl exec -it $APP_POD -- php artisan key:generate --show --no-ansi ) kubectl create secret generic letsplan-dev \\ --from-literal = \"APP_KEY= ${ APP_KEY } \" kubectl delete pod $APP_POD Forward port to access app: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $APP_POD 8080 :80 Open http://localhost:8080 Populate database: Load a database dump, or edit the letsplan ConfigMap to connect to the online database instead of populating the local one and then restart the pod. Generate tiles: Open http://localhost:8080/mbtile to generate tiles.","title":"Kubernetes"},{"location":"development/k8s/#kubernetes","text":"Create a disposable local Kubernetes environment: kind create cluster Install Helm chart: helm install letsplan ./helm-chart \\ --set workloads.app.secrets.app = letsplan-dev \\ --set images.app.repository = ghcr.io/jarvusinnovations/letsplanorg/laravel-site !!! warning Kind is incompatible with docker.pkg.github.com and the urbanSpatial organization does not have ghcr.io support enabled The above command overrides the release to use a ghcr.io-hosted image under Jarvus' organization. This image is not automatically updated when new versions are pushed/released on the urbanSpatial organization and must have updated container images manually pushed. Generate APP_KEY secret and restart pod: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) APP_KEY = $( kubectl exec -it $APP_POD -- php artisan key:generate --show --no-ansi ) kubectl create secret generic letsplan-dev \\ --from-literal = \"APP_KEY= ${ APP_KEY } \" kubectl delete pod $APP_POD Forward port to access app: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $APP_POD 8080 :80 Open http://localhost:8080 Populate database: Load a database dump, or edit the letsplan ConfigMap to connect to the online database instead of populating the local one and then restart the pod. Generate tiles: Open http://localhost:8080/mbtile to generate tiles.","title":"Kubernetes"},{"location":"operations/k8s/","text":"Kubernetes \u00b6 Using deployer-admin service account \u00b6 Download the letsplan-deployer.yaml attachment from the letsplan-deployer @ jarvus-live-cluster secret in BitWarden into your ~/.kube directory Activate the downloaded KUBECONFIG in your current terminal session: export KUBECONFIG = ~/.kube/letsplan-deployer.yaml Get the name of the currently running pods and store them in shell variables: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' ) Open interactive app shell \u00b6 kubectl exec -it $APP_POD -- bash Open interactive database shell \u00b6 kubectl exec -it $DB_POD -- psql -U admin laravel Run an artisan command \u00b6 kubectl exec -it $APP_POD -- php artisan migrate Run an SQL query \u00b6 echo 'SELECT * FROM users' | kubectl exec -i $DB_POD -- psql -U admin laravel Forward PostgreSQL port \u00b6 kubectl port-forward pods/ $DB_POD 5432 :5432 Database logins Default database credentials can be found in helm-chart/values.yaml","title":"Kubernetes"},{"location":"operations/k8s/#kubernetes","text":"","title":"Kubernetes"},{"location":"operations/k8s/#using-deployer-admin-service-account","text":"Download the letsplan-deployer.yaml attachment from the letsplan-deployer @ jarvus-live-cluster secret in BitWarden into your ~/.kube directory Activate the downloaded KUBECONFIG in your current terminal session: export KUBECONFIG = ~/.kube/letsplan-deployer.yaml Get the name of the currently running pods and store them in shell variables: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' )","title":"Using deployer-admin service account"},{"location":"operations/k8s/#open-interactive-app-shell","text":"kubectl exec -it $APP_POD -- bash","title":"Open interactive app shell"},{"location":"operations/k8s/#open-interactive-database-shell","text":"kubectl exec -it $DB_POD -- psql -U admin laravel","title":"Open interactive database shell"},{"location":"operations/k8s/#run-an-artisan-command","text":"kubectl exec -it $APP_POD -- php artisan migrate","title":"Run an artisan command"},{"location":"operations/k8s/#run-an-sql-query","text":"echo 'SELECT * FROM users' | kubectl exec -i $DB_POD -- psql -U admin laravel","title":"Run an SQL query"},{"location":"operations/k8s/#forward-postgresql-port","text":"kubectl port-forward pods/ $DB_POD 5432 :5432 Database logins Default database credentials can be found in helm-chart/values.yaml","title":"Forward PostgreSQL port"},{"location":"operations/postgresql/","text":"PostgreSQL \u00b6 Set up read only user \u00b6 This user is manually created on the production PostgreSQL instance to provide read-only access to local development instances: CREATE ROLE read_only LOGIN PASSWORD '{stored in bitwarden}' ; GRANT CONNECT ON DATABASE laravel TO read_only ; GRANT USAGE ON SCHEMA public TO read_only ; GRANT SELECT ON ALL TABLES IN SCHEMA public TO read_only ; The actual password is stored in the BitWarden shared entry read_only @ postgresql","title":"PostgreSQL"},{"location":"operations/postgresql/#postgresql","text":"","title":"PostgreSQL"},{"location":"operations/postgresql/#set-up-read-only-user","text":"This user is manually created on the production PostgreSQL instance to provide read-only access to local development instances: CREATE ROLE read_only LOGIN PASSWORD '{stored in bitwarden}' ; GRANT CONNECT ON DATABASE laravel TO read_only ; GRANT USAGE ON SCHEMA public TO read_only ; GRANT SELECT ON ALL TABLES IN SCHEMA public TO read_only ; The actual password is stored in the BitWarden shared entry read_only @ postgresql","title":"Set up read only user"}]}
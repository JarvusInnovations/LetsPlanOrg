{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 This will be the home of LetsPlan.org\u2019s technical documentation.","title":"Welcome"},{"location":"#welcome","text":"This will be the home of LetsPlan.org\u2019s technical documentation.","title":"Welcome"},{"location":"development/docs/","text":"Documentation \u00b6 Working with live preview \u00b6 Install Chef Habitat Install Habitat packages: sudo hab pkg install jarvus/mkdocs Create python environment: hab pkg exec jarvus/mkdocs python -m venv \"./.venv\" source \"./.venv/bin/activate\" pip install --upgrade pip pip install mkdocs mkdocs-material mkdocs-awesome-pages-plugin fontawesome_markdown Launch live preview server: mkdocs serve Open http://localhost:8000/","title":"Documentation"},{"location":"development/docs/#documentation","text":"","title":"Documentation"},{"location":"development/docs/#working-with-live-preview","text":"Install Chef Habitat Install Habitat packages: sudo hab pkg install jarvus/mkdocs Create python environment: hab pkg exec jarvus/mkdocs python -m venv \"./.venv\" source \"./.venv/bin/activate\" pip install --upgrade pip pip install mkdocs mkdocs-material mkdocs-awesome-pages-plugin fontawesome_markdown Launch live preview server: mkdocs serve Open http://localhost:8000/","title":"Working with live preview"},{"location":"development/k8s/","text":"Kubernetes \u00b6 Create a disposable local Kubernetes environment: kind create cluster Install Helm chart: helm install letsplan ./helm-chart \\ --set workloads.app.secrets.app = letsplan-dev Generate APP_KEY secret and restart pod: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) APP_KEY = $( kubectl exec -it $APP_POD -- php artisan key:generate --show --no-ansi ) kubectl create secret generic letsplan-dev \\ --from-literal = \"APP_KEY= ${ APP_KEY } \" kubectl delete pod $APP_POD Forward port to access app: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $APP_POD 8080 :80 Open http://localhost:8080 Populate database: Load a database dump, or edit the letsplan ConfigMap to connect to the online database instead of populating the local one and then restart the pod. Generate tiles: Open http://localhost:8080/mbtile to generate tiles.","title":"Kubernetes"},{"location":"development/k8s/#kubernetes","text":"Create a disposable local Kubernetes environment: kind create cluster Install Helm chart: helm install letsplan ./helm-chart \\ --set workloads.app.secrets.app = letsplan-dev Generate APP_KEY secret and restart pod: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) APP_KEY = $( kubectl exec -it $APP_POD -- php artisan key:generate --show --no-ansi ) kubectl create secret generic letsplan-dev \\ --from-literal = \"APP_KEY= ${ APP_KEY } \" kubectl delete pod $APP_POD Forward port to access app: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $APP_POD 8080 :80 Open http://localhost:8080 Populate database: Load a database dump, or edit the letsplan ConfigMap to connect to the online database instead of populating the local one and then restart the pod. Generate tiles: Open http://localhost:8080/mbtile to generate tiles.","title":"Kubernetes"},{"location":"development/local-dev/","text":"Local development \u00b6 Initial setup \u00b6 Copy .env.example to .env Change the web port from 7780 to something unsused if you have a port conflict. Change the MailHog web port from 8725 to something unsused if you have a port conflict. If you have another Postgres running on 5432, add a line to your .env like FORWARD_DB_PORT=5433 Composer install with your host computer\u2019s PHP/Composer. composer install OR, use docker to run initial composer install: docker run -ti --rm -v $( pwd ) :/app -w /app composer:2.0 composer install Bring up containers: ./vendor/bin/sail up -d Generate unique app key: ./vendor/bin/sail artisan key:generate Run all database migrations: ./vendor/bin/sail artisan migrate Build frontend: ./vendor/bin/sail yarn install MapBox setup \u00b6 Edit the .env and add a vector (pbf) source URL to MBTILE_URL : MBTILE_URL = \"https://api.maptiler.com/tiles/contours/11/599/770.pbf?key=yd4rAVOD6ZdfBCcbKnIE\" Tip You might change fill-color to fill-outline-color in resources/js/Shared/MapboxMap.vue for this example. Importing data \u00b6 Import PWD Parcel definitions. A file will be saved into ./storage/app/ and imported into the parcel table. Run: ./vendor/bin/sail artisan lp:import-parcels Copy your alteration permits and new construction permits CSV files into ./storage/app/ Run: ./vendor/bin/sail artisan lp:import-bldg-permits alteration_permits.csv Run: ./vendor/bin/sail artisan lp:import-bldg-permits new_construction_permits.csv Run: ./vendor/bin/sail artisan lp:import-rco Import Atlas API data to connect OPA and PWD parcel IDs: ./vendor/bin/sail artisan lp:scrape-atlas --key = ${ your gatekeeper key } Creating a view of just 1 community \u00b6 CREATE MATERIALIZED VIEW project_parcels_1 AS SELECT p . * FROM parcel AS p INNER JOIN rco AS n ON ST_Intersects ( ST_GeomFromGeoJSON ( p . geo_json ), ST_GeomFromGeoJSON ( n . geo_json )) WHERE n . object_id = '23641' Extract the parcels for one community and compile them into MapBox tiles: ./vendor/bin/sail artisan lp:stream-parcel-geo-json project_parcels_2 > project1.geojson docker run --rm -ti \\ -v $( pwd ) :/app \\ -w /app \\ strikehawk/tippecanoe \\ tippecanoe -z20 -Z8 -f --name = urban-areas -l urban-areas --output = storage/app/urban_area.mbtiles project1.geojson Running Commands in Dev Environment \u00b6 Artisan / Laravel \u00b6 You can pass artisan commands into the container like this: ./vendor/bin/sail artisan tinker ./vendor/bin/sail artisan migrate:status Yarn \u00b6 You can pass yarn commands into the container like this: ./vendor/bin/sail yarn install ./vendor/bin/sail yarn add pkg Postgres \u00b6 You run an interactive psql shell like this: ./vendor/bin/sail psql PHP / Composer \u00b6 You run composer , php and root-shell commands: ./vendor/bin/sail composer require --dev pkg ./vendor/bin/sail php -v ./vendor/bin/sail root-shell","title":"Local development"},{"location":"development/local-dev/#local-development","text":"","title":"Local development"},{"location":"development/local-dev/#initial-setup","text":"Copy .env.example to .env Change the web port from 7780 to something unsused if you have a port conflict. Change the MailHog web port from 8725 to something unsused if you have a port conflict. If you have another Postgres running on 5432, add a line to your .env like FORWARD_DB_PORT=5433 Composer install with your host computer\u2019s PHP/Composer. composer install OR, use docker to run initial composer install: docker run -ti --rm -v $( pwd ) :/app -w /app composer:2.0 composer install Bring up containers: ./vendor/bin/sail up -d Generate unique app key: ./vendor/bin/sail artisan key:generate Run all database migrations: ./vendor/bin/sail artisan migrate Build frontend: ./vendor/bin/sail yarn install","title":"Initial setup"},{"location":"development/local-dev/#mapbox-setup","text":"Edit the .env and add a vector (pbf) source URL to MBTILE_URL : MBTILE_URL = \"https://api.maptiler.com/tiles/contours/11/599/770.pbf?key=yd4rAVOD6ZdfBCcbKnIE\" Tip You might change fill-color to fill-outline-color in resources/js/Shared/MapboxMap.vue for this example.","title":"MapBox setup"},{"location":"development/local-dev/#importing-data","text":"Import PWD Parcel definitions. A file will be saved into ./storage/app/ and imported into the parcel table. Run: ./vendor/bin/sail artisan lp:import-parcels Copy your alteration permits and new construction permits CSV files into ./storage/app/ Run: ./vendor/bin/sail artisan lp:import-bldg-permits alteration_permits.csv Run: ./vendor/bin/sail artisan lp:import-bldg-permits new_construction_permits.csv Run: ./vendor/bin/sail artisan lp:import-rco Import Atlas API data to connect OPA and PWD parcel IDs: ./vendor/bin/sail artisan lp:scrape-atlas --key = ${ your gatekeeper key }","title":"Importing data"},{"location":"development/local-dev/#creating-a-view-of-just-1-community","text":"CREATE MATERIALIZED VIEW project_parcels_1 AS SELECT p . * FROM parcel AS p INNER JOIN rco AS n ON ST_Intersects ( ST_GeomFromGeoJSON ( p . geo_json ), ST_GeomFromGeoJSON ( n . geo_json )) WHERE n . object_id = '23641' Extract the parcels for one community and compile them into MapBox tiles: ./vendor/bin/sail artisan lp:stream-parcel-geo-json project_parcels_2 > project1.geojson docker run --rm -ti \\ -v $( pwd ) :/app \\ -w /app \\ strikehawk/tippecanoe \\ tippecanoe -z20 -Z8 -f --name = urban-areas -l urban-areas --output = storage/app/urban_area.mbtiles project1.geojson","title":"Creating a view of just 1 community"},{"location":"development/local-dev/#running-commands-in-dev-environment","text":"","title":"Running Commands in Dev Environment"},{"location":"development/local-dev/#artisan-laravel","text":"You can pass artisan commands into the container like this: ./vendor/bin/sail artisan tinker ./vendor/bin/sail artisan migrate:status","title":"Artisan / Laravel"},{"location":"development/local-dev/#yarn","text":"You can pass yarn commands into the container like this: ./vendor/bin/sail yarn install ./vendor/bin/sail yarn add pkg","title":"Yarn"},{"location":"development/local-dev/#postgres","text":"You run an interactive psql shell like this: ./vendor/bin/sail psql","title":"Postgres"},{"location":"development/local-dev/#php-composer","text":"You run composer , php and root-shell commands: ./vendor/bin/sail composer require --dev pkg ./vendor/bin/sail php -v ./vendor/bin/sail root-shell","title":"PHP / Composer"},{"location":"development/quick-start/","text":"Quick start \u00b6 Initialize new .env file: cp .env.example .env Tip Change the web port from 7780 to something unsused if you have a port conflict. Change the MailHog web port from 8725 to something unsused if you have a port conflict. If you have another Postgres running on 5432, add a line to your .env like FORWARD_DB_PORT=5433 Configure .env to use online/remote database and map tiles so you can skip loading data and building tiles locally: MBTILE_URL = \"https://letsplan.live.k8s.jarv.us/urban/{z}/{x}/{y}.pbf\" MIX_MBTILE_URL = \" ${ MBTILE_URL } \" DB_HOST = WORKSTATION_LAN_IP DB_PORT = 5433 DB_USERNAME = read_only DB_PASSWORD = FROM_BITWARDEN The password is available in BitWarden under the entry read_only @ postgresql Note The above configuration points DB_PORT at 5433 because we\u2019ll be opening a tunnel from there to the online/remote database with the kubectl port-forward command in step 4. We use that port to avoid conflict with the local PostgreSQL instance step 5 will still spin up on the default port 5432 , but which we will be ignoring and not loading any data into. Use Docker to install PHP dependencies: docker run -ti --rm -v $( pwd ) :/app -w /app composer:2.0 composer install Open a tunnel from the online PostgreSQL database to local port 5433 : export KUBECONFIG = ~/.kube/letsplan-deployer.yaml DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $DB_POD --address 0 .0.0.0 5433 :5432 Download letsplan-deployer.yaml from the letsplan-deployer @ jarvus-live-cluster entry in BitWarden Start local Docker environment with Laravel Sail: ./vendor/bin/sail up -d Generate unique local app key: ./vendor/bin/sail artisan key:generate Install frontend dependencies: ./vendor/bin/sail yarn install Execute a frontend build: ./vendor/bin/sail yarn production","title":"Quick start"},{"location":"development/quick-start/#quick-start","text":"Initialize new .env file: cp .env.example .env Tip Change the web port from 7780 to something unsused if you have a port conflict. Change the MailHog web port from 8725 to something unsused if you have a port conflict. If you have another Postgres running on 5432, add a line to your .env like FORWARD_DB_PORT=5433 Configure .env to use online/remote database and map tiles so you can skip loading data and building tiles locally: MBTILE_URL = \"https://letsplan.live.k8s.jarv.us/urban/{z}/{x}/{y}.pbf\" MIX_MBTILE_URL = \" ${ MBTILE_URL } \" DB_HOST = WORKSTATION_LAN_IP DB_PORT = 5433 DB_USERNAME = read_only DB_PASSWORD = FROM_BITWARDEN The password is available in BitWarden under the entry read_only @ postgresql Note The above configuration points DB_PORT at 5433 because we\u2019ll be opening a tunnel from there to the online/remote database with the kubectl port-forward command in step 4. We use that port to avoid conflict with the local PostgreSQL instance step 5 will still spin up on the default port 5432 , but which we will be ignoring and not loading any data into. Use Docker to install PHP dependencies: docker run -ti --rm -v $( pwd ) :/app -w /app composer:2.0 composer install Open a tunnel from the online PostgreSQL database to local port 5433 : export KUBECONFIG = ~/.kube/letsplan-deployer.yaml DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' ) kubectl port-forward pods/ $DB_POD --address 0 .0.0.0 5433 :5432 Download letsplan-deployer.yaml from the letsplan-deployer @ jarvus-live-cluster entry in BitWarden Start local Docker environment with Laravel Sail: ./vendor/bin/sail up -d Generate unique local app key: ./vendor/bin/sail artisan key:generate Install frontend dependencies: ./vendor/bin/sail yarn install Execute a frontend build: ./vendor/bin/sail yarn production","title":"Quick start"},{"location":"operations/k8s/","text":"Kubernetes \u00b6 Using deployer-admin service account \u00b6 Download the letsplan-deployer.yaml attachment from the letsplan-deployer @ jarvus-live-cluster secret in BitWarden into your ~/.kube directory Activate the downloaded KUBECONFIG in your current terminal session: export KUBECONFIG = ~/.kube/letsplan-deployer.yaml Get the name of the currently running pods and store them in shell variables: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' ) Open interactive app shell \u00b6 kubectl exec -it $APP_POD -- bash Open interactive database shell \u00b6 kubectl exec -it $DB_POD -- psql -U admin laravel Run an artisan command \u00b6 kubectl exec -it $APP_POD -- php artisan migrate Run an SQL query \u00b6 echo 'SELECT * FROM users' | kubectl exec -i $DB_POD -- psql -U admin laravel Forward PostgreSQL port \u00b6 kubectl port-forward pods/ $DB_POD 5432 :5432 Database logins Default database credentials can be found in helm-chart/values.yaml","title":"Kubernetes"},{"location":"operations/k8s/#kubernetes","text":"","title":"Kubernetes"},{"location":"operations/k8s/#using-deployer-admin-service-account","text":"Download the letsplan-deployer.yaml attachment from the letsplan-deployer @ jarvus-live-cluster secret in BitWarden into your ~/.kube directory Activate the downloaded KUBECONFIG in your current terminal session: export KUBECONFIG = ~/.kube/letsplan-deployer.yaml Get the name of the currently running pods and store them in shell variables: APP_POD = $( kubectl get pod -l component = app -o jsonpath = '{.items[0].metadata.name}' ) DB_POD = $( kubectl get pod -l component = database -o jsonpath = '{.items[0].metadata.name}' )","title":"Using deployer-admin service account"},{"location":"operations/k8s/#open-interactive-app-shell","text":"kubectl exec -it $APP_POD -- bash","title":"Open interactive app shell"},{"location":"operations/k8s/#open-interactive-database-shell","text":"kubectl exec -it $DB_POD -- psql -U admin laravel","title":"Open interactive database shell"},{"location":"operations/k8s/#run-an-artisan-command","text":"kubectl exec -it $APP_POD -- php artisan migrate","title":"Run an artisan command"},{"location":"operations/k8s/#run-an-sql-query","text":"echo 'SELECT * FROM users' | kubectl exec -i $DB_POD -- psql -U admin laravel","title":"Run an SQL query"},{"location":"operations/k8s/#forward-postgresql-port","text":"kubectl port-forward pods/ $DB_POD 5432 :5432 Database logins Default database credentials can be found in helm-chart/values.yaml","title":"Forward PostgreSQL port"},{"location":"operations/postgresql/","text":"PostgreSQL \u00b6 Set up read only user \u00b6 This user is manually created on the production PostgreSQL instance to provide read-only access to local development instances: CREATE ROLE read_only LOGIN PASSWORD '{stored in bitwarden}' ; GRANT CONNECT ON DATABASE laravel TO read_only ; GRANT USAGE ON SCHEMA public TO read_only ; GRANT SELECT ON ALL TABLES IN SCHEMA public TO read_only ; The actual password is stored in the BitWarden shared entry read_only @ postgresql","title":"PostgreSQL"},{"location":"operations/postgresql/#postgresql","text":"","title":"PostgreSQL"},{"location":"operations/postgresql/#set-up-read-only-user","text":"This user is manually created on the production PostgreSQL instance to provide read-only access to local development instances: CREATE ROLE read_only LOGIN PASSWORD '{stored in bitwarden}' ; GRANT CONNECT ON DATABASE laravel TO read_only ; GRANT USAGE ON SCHEMA public TO read_only ; GRANT SELECT ON ALL TABLES IN SCHEMA public TO read_only ; The actual password is stored in the BitWarden shared entry read_only @ postgresql","title":"Set up read only user"}]}